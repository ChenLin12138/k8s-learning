# 14.计算资源管理
本章内容涵盖
- 为容器申请cpu,内存以及其他计算资源
- 配置CPU,内存的硬限制
- 理解pod的Qos机制
- 为命名空间中每个pod配置默认，最大，最小资源限制
- 为命名空间配置可用资源总数

## 14.1 为pod中的容器申请资源
我们创建一个pod时，可以指定容易对CPU和内存的资源请求量(request)以及资源的限制量(limit)。他们并不在pod中定义。而是针对每个容器单独指定。
### 14.1.1 创建包含资源requests的pod
cpu指定了cpu大小，memory指定了内存大小,200m表示，我们在1000m中，他需要占用1/5的cpu时钟。
```
apiVersion: v1
kind: Pod
metadata:
  name: requests-pod
spec:
  containers:
  - image: busybox
    command: ["dd", "if=/dev/zero", "of=/dev/null"]
    name: main
    resources:
      requests:
        cpu: 200m
        memory: 10Mi
```
### 14.1.2 资源request如何影响调度
指定的cpu大小不是实际使用的大小。他们考虑的是自愿请求量，而不是实际使用的资源量。
## 14.2 限制容器的可用资源
设置pod的容器资源申请量保证了每个容器能够获得它所需要资源的最小值。现在我们来看硬币的另外一面。容器可以消耗资源的最大量。
### 14.2.1 设置容器可使用资源量的硬限制
**创建一个带有资源limit的pod**
下面限制了只能使用一核的cpu
```
apiVersion: v1
kind: Pod
metadata:
  name: limited-pod
spec:
  containers:
  - image: busybox
    command: ["dd", "if=/dev/zero", "of=/dev/null"]
    name: main
    resources:
      limits:
        cpu: 1
        memory: 20Mi
```
**可超卖的limit**
与资源request不同的是，资源limits不受节点可分配资源量的约束。所有limit的总和允许超过节点资源总量的100%。k8s如何决定杀掉哪些容器。不过只要单个容器尝试使用比自己指定的limit更多的资源时。也可能被杀掉。
### 14.2.2超过limits
### 14.3 了解pod Qos等级
BestEffort(最低优先级，没有设置limit或者request，最坏情况下分部到cp时间，同时需要为其它的pod释放内存的时候，他会第一批被杀死。不过他美誉分配limit,那么当资源充足时，他可以使用任意多的内存)
Burstable()
Guaranteed（最高优先，设置的imit和request相等）
**如何处理相同Qos等级的容器**
每个运行的进程中都有一个称为OOM分数的值。系统通过比较多有运行进程的OOM分数来选择要杀掉的进程。系统更喜欢杀掉系统实际使用量占系统内存申请量更高的容器。

## 14.4 为命名空间中的pod设置默认的requests和limits
### 14.4.1 LimitRange
用户通过创建一个LimitRange资源来避免必须配置每个容器。

## 14.5 限制命名空间中的可用资源总量
### 14.5.1 ResourceQuota资源介绍
使用ResourceQuota限制命名空间中所有pod允许使用的CPU和内存总量。

## 14.6 监控pod的资源使用量
设置合适的requests和limits对充分利用Kubernetes集群资源来说十分重要。如果requests设置的太高，集群节点的利用率就会比较低，这样白白浪费了金钱，如果设置的太低，应用就会处于cpu饥饿状态。
### 14.6.1 收集，获取实际资源使用情况
kubelet自身包含了一个名为cAdivsor的agent。他会收集整个节点和节点上运行的所有单独容器的资源消耗情况。
显示集群节点的cpu和内存使用量
```
k top nod
```
### 14.6.2 保存并分析历史资源的使用统计信息
InfluxDB和Grafana
InfluxDB是一个用于存储应用指标，以及监控数据库的开源时序数据库。Grafana是一个拥有着华丽的web控制台的数据分析和可视化套件。
